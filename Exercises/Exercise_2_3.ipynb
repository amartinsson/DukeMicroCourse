{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import mini MD modules\n",
    "from miniMD import models\n",
    "from miniMD import samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a binary classification problem, for a given set of paired data $(x_i,y_i)_{1 \\leq i \\leq N}$, where $y_i \\in \\mathbb{R}^d$ denotes the predictor variable and $y_i \\in \\{0, 1\\}$ the response variable. Let $X_i$ and $Y_i$ as described above be i.i.d. random variables associated with the observations $(y_i,z_i)$, respectively. A common way to model the dependence between the predictor variable and the response variable in binary classification problems is to assume that the conditional probability of the event $Y_i = 1$ given $X_i$ is described by the values of the logistic function evaluated at a linear transformation of $X_i$, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y_i =1|X_i)=f( x_i \\beta^T\\,)\n",
    "$$\n",
    "\n",
    "hence \n",
    "$$\\mathbb{P}(Y_i \\beta^T X_i) = f(Y_i \\beta^T X_i),$$\n",
    "where\n",
    "$$\n",
    "f(s) = \\frac{1}{1+e^{-s}}.\n",
    "$$\n",
    "is the logistic function and the weights w ∈ Rn define the linear transformation. In a Bayesian setup, the weights are considered to be random variables distributed according to a prior distribution, w ∼ π. By Bayes rule, the posterior distribution over w is then found to be,\n",
    "$$\n",
    "p(\\beta | x,y) \\propto \\pi(\\beta) p(y, | x, \\beta) = \\pi(\\beta) \\prod_{i=1}^N f( x_i \\beta^T\\, y_i ). \n",
    "$$\n",
    "Using the posterior distribution we can predict the class label of a new data point as \n",
    "$$\n",
    "\\mathbb{P}[y_{pred} | x_{pred},x,y] = \\int f(x_{pred}^T\\beta) p(\\beta | x,y) d \\beta\n",
    "$$\n",
    "In practice the integral on the left hand side of the equation is intractable. This is were sampling comes into play. One generate a sample $(\\beta^(k))_{1\\leq k \\leq N_{steps}}$ from the posterior distribution and approximate the integral term as \n",
    "$$\n",
    "\\int f(x_{pred}^T\\beta) p(\\beta | x,y) d \\beta  \\approx \\frac{1}{N_{steps}}\\sum_{k=1}^{N_{steps}} f(x_{pred}^T\\beta^{(k)})\n",
    "$$\n",
    "\n",
    "In this exercise we will consider a simple logistic regression classfier using a synthetic dataset of $N$ paired observations $(x_i,y_i)_{1\\leq i \\leq N}$, with $x_i \\in \\mathbb{R}^2$ being the predictor variable and $y_i\\in \\{0,1\\}$ being the class label as a training set. The code below creates such a synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=11) #Fix seed \n",
    "\n",
    "data_dim = 2 # Dimension of predictor variable\n",
    "Ndata1 = 10  # Number of points with class label 0\n",
    "Ndata2 = 10  # Number of points with class label 1\n",
    "\n",
    "mu1 = np.array([-4,0]) # mean of predictor variables with class label 0\n",
    "mu2 =  np.array([4,0]) # mean of predictor variables with class label 1\n",
    "cov1 = np.eye(data_dim) # covariance of predictor variables with class label 0\n",
    "cov2 = np.eye(data_dim) # covariance of predictor variables with class label 1\n",
    "\n",
    "\n",
    "# Sample data points \n",
    "X1 = np.random.multivariate_normal(mu1,cov1,size=Ndata1)\n",
    "Y1 = np.zeros(Ndata1)\n",
    "X2 = np.random.multivariate_normal(mu2,cov2,size=Ndata2)\n",
    "Y2 = np.ones(Ndata2)\n",
    "\n",
    "X = np.concatenate((X1,X2))\n",
    "Y = np.concatenate((Y1,Y2)) \n",
    "\n",
    "\n",
    "data = [X,Y] # data set in the format used in the logistic regression model below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the data set using the code the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2EVEIqNiFxGJjIpdRCQy/w+JEKXpsXw+XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ffda8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndata = Y.shape[0]\n",
    "color_dict= {0:'red', 1 :'blue'}\n",
    "colors = [color_dict[Y[i]] for i in range(ndata)]\n",
    "plt.scatter(X[:,0],X[:,1], c=colors)\n",
    "plt.title('Data') \n",
    "plt.xlim([mu1[0]-3*np.sqrt(cov1[0,0]),+mu2[0]+3*np.sqrt(cov2[0,0])])\n",
    "plt.ylim([mu1[1]-3*np.sqrt(cov1[1,1]),+mu2[1]+3*np.sqrt(cov2[1,1])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A suitable logistic regression model specifying a posterior distribution $p(\\beta | x,y)$ of a form as described above is implemented in the class \"BayesianLogisticRegression\". The implemented regression model assumes a Gaussian prior. The code below initializes the classifier model we will use in the following. \n",
    " - Note: In the code $q$ should be interpreted as $\\beta$, i.e., the output of our sampler corresponds to trajectory of samples distributed according to $p(\\beta | x,y)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q0 = np.zeros(data_dim)\n",
    "p0 = np.random.normal(0., 1., data_dim)\n",
    "model = models.BayesianLogisticRegression(prior_mean = np.zeros(data_dim),\n",
    "                                               prior_cov = 100*np.eye(data_dim),\n",
    "                                               data = [X,Y], \n",
    "                                               q=q0, \n",
    "                                               p=p0\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "- Set up an Ensbemble Quasi Newton sampler to sample from the posterior of the Bayesion logistic regression model specified above. It is recommended to use 10 replicas and a stepsize of $\\Delta t = .01$. Ensure that the number of time steps is sufficiently large that you get good exploration of your sampling space. (Hint: You may want to inspect the trace plot of $\\beta_1$ and $\\beta_2$ for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "After you have obtained a sample trajectory using the Quasi Ensemble Newton method, you can ue the below code to plot the prediction $\\mathbb{P}[y_{pred} | x_{pred},x,y]$ for points on the grid $x_{pred} \\in$ grid. Where grid = xx1 $\\times$ xx2, with the vectors xx1 and xx2  as specified below. \n",
    "If computations take to much time you may want to adapt the values of Nx1, Nx2, Neval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nx1 = 50\n",
    "Nx2 = 50\n",
    "xx1 = np.linspace(mu1[0]-3*np.sqrt(cov1[0,0]),+mu2[0]+3*np.sqrt(cov2[0,0]),Nx1)\n",
    "xx2 = np.linspace(mu1[1]-3*np.sqrt(cov1[1,1]),+mu2[1]+3*np.sqrt(cov2[1,1]),Nx2)\n",
    "\n",
    "figb, axb = model.plot_prediction(q_trajectory, grid=[xx1,xx2], Neval=100 )\n",
    "figb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus tasks \n",
    "\n",
    "You may want to explore how the training set determines the conditioning of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
